name: "MY_MN_full_deploy"
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param { shape: { dim: 1 dim: 3 dim: 224 dim: 224 } }
}
layer {
    name: "conv1"
    type: "Convolution"
    bottom: "data"
    top: "conv1"
    param {
        lr_mult: 1
        decay_mult: 1
    }
    convolution_param {
        num_output: 32
        pad: 1
        kernel_size: 3
        stride: 2
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    name: "conv1/bn"
    type: "BatchNorm"
    bottom: "conv1"
    top: "conv1/bn"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
}
layer {
    name: "conv1/bn_scale"
    type: "Scale"
    bottom: "conv1/bn"
    top: "conv1/bn"
    scale_param {
        bias_term: true
    }
}
layer {
    name: "relu1"
    type: "ReLU"
    bottom: "conv1/bn"
    top: "conv1/bn"
}
#####
layer {
    name: "conv2/3x3"
    type: "Convolution"
    bottom: "conv1/bn"
    top: "conv2/3x3"
    param {
        lr_mult: 1
        decay_mult: 1
    }
    convolution_param {
        num_output: 32
        pad: 1
        kernel_size: 3
        stride: 1
        group: 32
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    name: "conv2/3x3/bn"
    type: "BatchNorm"
    bottom: "conv2/3x3"
    top: "conv2/3x3/bn"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
}
layer {
    name: "conv2/3x3/scale"
    type: "Scale"
    bottom: "conv2/3x3/bn"
    top: "conv2/3x3/bn"
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv2/relu1"
    type: "ReLU"
    bottom: "conv2/3x3/bn"
    top: "conv2/3x3/bn"
}
layer {
    name: "conv2/1x1"
    type: "Convolution"
    bottom: "conv2/3x3/bn"
    top: "conv2/1x1"
    param {
        lr_mult: 1
        decay_mult: 1
    }
    convolution_param {
        num_output: 64
        pad: 0
        kernel_size: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    name: "conv2/1x1/bn"
    type: "BatchNorm"
    bottom: "conv2/1x1"
    top: "conv2/1x1/bn"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
}
layer {
    name: "conv2/1x1/scale"
    type: "Scale"
    bottom: "conv2/1x1/bn"
    top: "conv2/1x1/bn"
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv2/relu2"
    type: "ReLU"
    bottom: "conv2/1x1/bn"
    top: "conv2/1x1/bn"
}
#####
layer {
    name: "conv3/3x3"
    type: "Convolution"
    bottom: "conv2/1x1/bn"
    top: "conv3/3x3"
    param {
        lr_mult: 1
        decay_mult: 1
    }
    convolution_param {
        num_output: 64
        pad: 1
        kernel_size: 3
        stride: 2
        group: 64
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    name: "conv3/3x3/bn"
    type: "BatchNorm"
    bottom: "conv3/3x3"
    top: "conv3/3x3/bn"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
}
layer {
    name: "conv3/3x3/scale"
    type: "Scale"
    bottom: "conv3/3x3/bn"
    top: "conv3/3x3/bn"
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv3/relu1"
    type: "ReLU"
    bottom: "conv3/3x3/bn"
    top: "conv3/3x3/bn"
}
layer {
    name: "conv3/1x1"
    type: "Convolution"
    bottom: "conv3/3x3/bn"
    top: "conv3/1x1"
    param {
        lr_mult: 1
        decay_mult: 1
    }
    convolution_param {
        num_output: 128
        pad: 0
        kernel_size: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    name: "conv3/1x1/bn"
    type: "BatchNorm"
    bottom: "conv3/1x1"
    top: "conv3/1x1/bn"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
}
layer {
    name: "conv3/1x1/scale"
    type: "Scale"
    bottom: "conv3/1x1/bn"
    top: "conv3/1x1/bn"
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv3/relu2"
    type: "ReLU"
    bottom: "conv3/1x1/bn"
    top: "conv3/1x1/bn"
}
#######
layer {
    name: "conv4/3x3"
    type: "Convolution"
    bottom: "conv3/1x1/bn"
    top: "conv4/3x3"
    param {
        lr_mult: 1
        decay_mult: 1
    }
    convolution_param {
        num_output: 128
        pad: 1
        kernel_size: 3
        stride: 1
        group: 128
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    name: "conv4/3x3/bn"
    type: "BatchNorm"
    bottom: "conv4/3x3"
    top: "conv4/3x3/bn"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
}
layer {
    name: "conv4/3x3/scale"
    type: "Scale"
    bottom: "conv4/3x3/bn"
    top: "conv4/3x3/bn"
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv4/relu1"
    type: "ReLU"
    bottom: "conv4/3x3/bn"
    top: "conv4/3x3/bn"
}
layer {
    name: "conv4/1x1"
    type: "Convolution"
    bottom: "conv4/3x3/bn"
    top: "conv4/1x1"
    param {
        lr_mult: 1
        decay_mult: 1
    }
    convolution_param {
        num_output: 128
        pad: 0
        kernel_size: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    name: "conv4/1x1/bn"
    type: "BatchNorm"
    bottom: "conv4/1x1"
    top: "conv4/1x1/bn"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
}
layer {
    name: "conv4/1x1/scale"
    type: "Scale"
    bottom: "conv4/1x1/bn"
    top: "conv4/1x1/bn"
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv4/relu2"
    type: "ReLU"
    bottom: "conv4/1x1/bn"
    top: "conv4/1x1/bn"
}
#####
layer {
    name: "conv5/3x3"
    type: "Convolution"
    bottom: "conv4/1x1/bn"
    top: "conv5/3x3"
    param {
        lr_mult: 1
        decay_mult: 1
    }
    convolution_param {
        num_output: 128
        pad: 1
        kernel_size: 3
        stride: 2
        group: 128
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    name: "conv5/3x3/bn"
    type: "BatchNorm"
    bottom: "conv5/3x3"
    top: "conv5/3x3/bn"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
}
layer {
    name: "conv5/3x3/scale"
    type: "Scale"
    bottom: "conv5/3x3/bn"
    top: "conv5/3x3/bn"
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv5/relu1"
    type: "ReLU"
    bottom: "conv5/3x3/bn"
    top: "conv5/3x3/bn"
}
layer {
  name: "conv5/1x1"
  type: "Convolution"
  bottom: "conv5/3x3/bn"
  top: "conv5/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
    name: "conv5/1x1/bn"
    type: "BatchNorm"
    bottom: "conv5/1x1"
    top: "conv5/1x1/bn"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
}
layer {
    name: "conv5/1x1/scale"
    type: "Scale"
    bottom: "conv5/1x1/bn"
    top: "conv5/1x1/bn"
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv5/relu2"
    type: "ReLU"
    bottom: "conv5/1x1/bn"
    top: "conv5/1x1/bn"
}
#####
layer {
    name: "conv6/3x3"
    type: "Convolution"
    bottom: "conv5/1x1/bn"
    top: "conv6/3x3"
    param {
        lr_mult: 1
        decay_mult: 1
    }
    convolution_param {
        num_output: 256
        pad: 1
        kernel_size: 3
        stride: 1
        group: 256
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    name: "conv6/3x3/bn"
    type: "BatchNorm"
    bottom: "conv6/3x3"
    top: "conv6/3x3/bn"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
}
layer {
    name: "conv6/3x3/scale"
    type: "Scale"
    bottom: "conv6/3x3/bn"
    top: "conv6/3x3/bn"
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv6/relu1"
    type: "ReLU"
    bottom: "conv6/3x3/bn"
    top: "conv6/3x3/bn"
}
layer {
  name: "conv6/1x1"
  type: "Convolution"
  bottom: "conv6/3x3/bn"
  top: "conv6/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
    name: "conv6/1x1/bn"
    type: "BatchNorm"
    bottom: "conv6/1x1"
    top: "conv6/1x1/bn"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
}
layer {
    name: "conv6/1x1/scale"
    type: "Scale"
    bottom: "conv6/1x1/bn"
    top: "conv6/1x1/bn"
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv6/relu2"
    type: "ReLU"
    bottom: "conv6/1x1/bn"
    top: "conv6/1x1/bn"
}
########
layer {
    name: "conv7/3x3"
    type: "Convolution"
    bottom: "conv6/1x1/bn"
    top: "conv7/3x3"
    param {
        lr_mult: 1
        decay_mult: 1
    }
    convolution_param {
        num_output: 256
        pad: 1
        kernel_size: 3
        stride: 2
        group: 256
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    name: "conv7/3x3/bn"
    type: "BatchNorm"
    bottom: "conv7/3x3"
    top: "conv7/3x3/bn"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
}
layer {
    name: "conv7/3x3/scale"
    type: "Scale"
    bottom: "conv7/3x3/bn"
    top: "conv7/3x3/bn"
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv7/relu1"
    type: "ReLU"
    bottom: "conv7/3x3/bn"
    top: "conv7/3x3/bn"
}
layer {
  name: "conv7/1x1"
  type: "Convolution"
  bottom: "conv7/3x3/bn"
  top: "conv7/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
    name: "conv7/1x1/bn"
    type: "BatchNorm"
    bottom: "conv7/1x1"
    top: "conv7/1x1/bn"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
}
layer {
    name: "conv7/1x1/scale"
    type: "Scale"
    bottom: "conv7/1x1/bn"
    top: "conv7/1x1/bn"
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv7/relu2"
    type: "ReLU"
    bottom: "conv7/1x1/bn"
    top: "conv7/1x1/bn"
}
#####
layer {
    name: "conv8/3x3"
    type: "Convolution"
    bottom: "conv7/1x1/bn"
    top: "conv8/3x3"
    param {
        lr_mult: 1
        decay_mult: 1
    }
    convolution_param {
        num_output: 512
        pad: 1
        kernel_size: 3
        stride: 1
        group: 512
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    name: "conv8/3x3/bn"
    type: "BatchNorm"
    bottom: "conv8/3x3"
    top: "conv8/3x3/bn"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
}
layer {
    name: "conv8/3x3/scale"
    type: "Scale"
    bottom: "conv8/3x3/bn"
    top: "conv8/3x3/bn"
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv8/relu1"
    type: "ReLU"
    bottom: "conv8/3x3/bn"
    top: "conv8/3x3/bn"
}
layer {
  name: "conv8/1x1"
  type: "Convolution"
  bottom: "conv8/3x3/bn"
  top: "conv8/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
    name: "conv8/1x1/bn"
    type: "BatchNorm"
    bottom: "conv8/1x1"
    top: "conv8/1x1/bn"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
}
layer {
    name: "conv8/1x1/scale"
    type: "Scale"
    bottom: "conv8/1x1/bn"
    top: "conv8/1x1/bn"
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv8/relu2"
    type: "ReLU"
    bottom: "conv8/1x1/bn"
    top: "conv8/1x1/bn"
}
#####
layer {
    name: "conv9/3x3"
    type: "Convolution"
    bottom: "conv8/1x1/bn"
    top: "conv9/3x3"
    param {
        lr_mult: 1
        decay_mult: 1
    }
    convolution_param {
        num_output: 512
        pad: 1
        kernel_size: 3
        stride: 1
        group: 512
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    name: "conv9/3x3/bn"
    type: "BatchNorm"
    bottom: "conv9/3x3"
    top: "conv9/3x3/bn"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
}
layer {
    name: "conv9/3x3/scale"
    type: "Scale"
    bottom: "conv9/3x3/bn"
    top: "conv9/3x3/bn"
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv9/relu1"
    type: "ReLU"
    bottom: "conv9/3x3/bn"
    top: "conv9/3x3/bn"
}
layer {
    name: "conv9/1x1"
    type: "Convolution"
    bottom: "conv9/3x3/bn"
    top: "conv9/1x1"
    param {
        lr_mult: 1
        decay_mult: 1
    }
    convolution_param {
        num_output: 512
        pad: 0
        kernel_size: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    name: "conv9/1x1/bn"
    type: "BatchNorm"
    bottom: "conv9/1x1"
    top: "conv9/1x1/bn"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
}
layer {
    name: "conv9/1x1/scale"
    type: "Scale"
    bottom: "conv9/1x1/bn"
    top: "conv9/1x1/bn"
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv9/relu2"
    type: "ReLU"
    bottom: "conv9/1x1/bn"
    top: "conv9/1x1/bn"
}
#####
layer {
    name: "conv10/3x3"
    type: "Convolution"
    bottom: "conv9/1x1/bn"
    top: "conv10/3x3"
    param {
        lr_mult: 1
        decay_mult: 1
    }
    convolution_param {
        num_output: 512
        pad: 1
        kernel_size: 3
        stride: 1
        group: 512
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    name: "conv10/3x3/bn"
    type: "BatchNorm"
    bottom: "conv10/3x3"
    top: "conv10/3x3/bn"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
}
layer {
    name: "conv10/3x3/scale"
    type: "Scale"
    bottom: "conv10/3x3/bn"
    top: "conv10/3x3/bn"
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv10/relu1"
    type: "ReLU"
    bottom: "conv10/3x3/bn"
    top: "conv10/3x3/bn"
}
layer {
  name: "conv10/1x1"
  type: "Convolution"
  bottom: "conv10/3x3/bn"
  top: "conv10/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
    name: "conv10/1x1/bn"
    type: "BatchNorm"
    bottom: "conv10/1x1"
    top: "conv10/1x1/bn"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
}
layer {
    name: "conv10/1x1/scale"
    type: "Scale"
    bottom: "conv10/1x1/bn"
    top: "conv10/1x1/bn"
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv10/relu2"
    type: "ReLU"
    bottom: "conv10/1x1/bn"
    top: "conv10/1x1/bn"
}
#####
layer {
    name: "conv11/3x3"
    type: "Convolution"
    bottom: "conv10/1x1/bn"
    top: "conv11/3x3"
    param {
        lr_mult: 1
        decay_mult: 1
    }
    convolution_param {
        num_output: 512
        pad: 1
        kernel_size: 3
        stride: 1
        group: 512
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    name: "conv11/3x3/bn"
    type: "BatchNorm"
    bottom: "conv11/3x3"
    top: "conv11/3x3/bn"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
}
layer {
    name: "conv11/3x3/scale"
    type: "Scale"
    bottom: "conv11/3x3/bn"
    top: "conv11/3x3/bn"
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv11/relu1"
    type: "ReLU"
    bottom: "conv11/3x3/bn"
    top: "conv11/3x3/bn"
}
layer {
  name: "conv11/1x1"
  type: "Convolution"
  bottom: "conv11/3x3/bn"
  top: "conv11/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
    name: "conv11/1x1/bn"
    type: "BatchNorm"
    bottom: "conv11/1x1"
    top: "conv11/1x1/bn"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
}
layer {
    name: "conv11/1x1/scale"
    type: "Scale"
    bottom: "conv11/1x1/bn"
    top: "conv11/1x1/bn"
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv11/relu2"
    type: "ReLU"
    bottom: "conv11/1x1/bn"
    top: "conv11/1x1/bn"
}
#####
layer {
    name: "conv12/3x3"
    type: "Convolution"
    bottom: "conv11/1x1/bn"
    top: "conv12/3x3"
    param {
        lr_mult: 1
        decay_mult: 1
    }
    convolution_param {
        num_output: 512
        pad: 1
        kernel_size: 3
        stride: 1
        group: 512
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    name: "conv12/3x3/bn"
    type: "BatchNorm"
    bottom: "conv12/3x3"
    top: "conv12/3x3/bn"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
}
layer {
    name: "conv12/3x3/scale"
    type: "Scale"
    bottom: "conv12/3x3/bn"
    top: "conv12/3x3/bn"
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv12/relu1"
    type: "ReLU"
    bottom: "conv12/3x3/bn"
    top: "conv12/3x3/bn"
}
layer {
  name: "conv12/1x1"
  type: "Convolution"
  bottom: "conv12/3x3/bn"
  top: "conv12/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
    name: "conv12/1x1/bn"
    type: "BatchNorm"
    bottom: "conv12/1x1"
    top: "conv12/1x1/bn"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
}
layer {
    name: "conv12/1x1/scale"
    type: "Scale"
    bottom: "conv12/1x1/bn"
    top: "conv12/1x1/bn"
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv12/relu2"
    type: "ReLU"
    bottom: "conv12/1x1/bn"
    top: "conv12/1x1/bn"
}
#####
layer {
    name: "conv13/3x3"
    type: "Convolution"
    bottom: "conv12/1x1/bn"
    top: "conv13/3x3"
    param {
        lr_mult: 1
        decay_mult: 1
    }
    convolution_param {
        num_output: 512
        pad: 1
        kernel_size: 3
        stride: 2
        group: 512
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    name: "conv13/3x3/bn"
    type: "BatchNorm"
    bottom: "conv13/3x3"
    top: "conv13/3x3/bn"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
}
layer {
    name: "conv13/3x3/scale"
    type: "Scale"
    bottom: "conv13/3x3/bn"
    top: "conv13/3x3/bn"
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv13/relu1"
    type: "ReLU"
    bottom: "conv13/3x3/bn"
    top: "conv13/3x3/bn"
}
layer {
  name: "conv13/1x1"
  type: "Convolution"
  bottom: "conv13/3x3/bn"
  top: "conv13/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
    name: "conv13/1x1/bn"
    type: "BatchNorm"
    bottom: "conv13/1x1"
    top: "conv13/1x1/bn"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
}
layer {
    name: "conv13/1x1/scale"
    type: "Scale"
    bottom: "conv13/1x1/bn"
    top: "conv13/1x1/bn"
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv13/relu2"
    type: "ReLU"
    bottom: "conv13/1x1/bn"
    top: "conv13/1x1/bn"
}
#####
layer {
    name: "conv14/3x3"
    type: "Convolution"
    bottom: "conv13/1x1/bn"
    top: "conv14/3x3"
    param {
        lr_mult: 1
        decay_mult: 1
    }
    convolution_param {
        num_output: 1024
        pad: 1
        kernel_size: 3
        stride: 1
        group: 1024
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    name: "conv14/3x3/bn"
    type: "BatchNorm"
    bottom: "conv14/3x3"
    top: "conv14/3x3/bn"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
}
layer {
    name: "conv14/3x3/scale"
    type: "Scale"
    bottom: "conv14/3x3/bn"
    top: "conv14/3x3/bn"
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv14/relu1"
    type: "ReLU"
    bottom: "conv14/3x3/bn"
    top: "conv14/3x3/bn"
}
layer {
  name: "conv14/1x1"
  type: "Convolution"
  bottom: "conv14/3x3/bn"
  top: "conv14/1x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 2
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
    name: "conv14/1x1/bn"
    type: "BatchNorm"
    bottom: "conv14/1x1"
    top: "conv14/1x1/bn"
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
    param {
        lr_mult: 0
        decay_mult: 0
    }
}
layer {
    name: "conv14/1x1/scale"
    type: "Scale"
    bottom: "conv14/1x1/bn"
    top: "conv14/1x1/bn"
    scale_param {
        bias_term: true
    }
}
layer {
    name: "conv14/relu2"
    type: "ReLU"
    bottom: "conv14/1x1/bn"
    top: "conv14/1x1/bn"
}
layer {
    name: "pool15"
    type: "Pooling"
    bottom: "conv14/1x1/bn"
    top: "pool15"
    pooling_param {
        pool: AVE
        kernel_size: 4
        global_pooling: false
    }
}
layer {
    name: "fc1-conv"
    type: "Convolution"
    bottom: "pool15"
    top: "fc1-conv"
    param {
        lr_mult: 1
        decay_mult: 1
    }
    convolution_param {
        num_output: 2
        kernel_size: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false 
    }
}
layer {
    name: "prob"
    type: "Softmax"
    bottom: "fc1-conv"
    top: "prob"
    loss_weight: 1 
}